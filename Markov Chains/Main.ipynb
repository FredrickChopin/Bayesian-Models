{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [0.6, 0.05, 0.1, 0.25],\n",
    "    [0.1, 0.05, 0.7, 0.15],\n",
    "    [0.05, 0.7, 0.1, 0.15],\n",
    "    [0.1, 0.1, 0.6, 0.2]\n",
    "]) #Transition matrix between states\n",
    "B = np.array([\n",
    "    [0.8, 0.2, 0.1, 0.5],\n",
    "    [0.1, 0.7, 0.7, 0.3],\n",
    "    [0.1, 0.1, 0.2, 0.2]\n",
    "]).T #We transpose B to be consistent with Dr.Kaminski's lectures\n",
    "pi = np.array([0.3, 0.1, 0.4, 0.2]) #The prior distribution over the ponds\n",
    "T = 1000 #Our L"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "For each algorithm, we implement two variations. One variation is without taking the $\\log$. It is implemented with matrix multiplication, when possible, for efficiency. The second variation is by taking the $\\log$ of the variables. We have found the function **np.logaddexp.reduce** to be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, T, A, B, pi):\n",
    "        self.T = T\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.pi = pi\n",
    "        self.log_B = np.log(self.B)\n",
    "        self.log_A = np.log(self.A)\n",
    "        self.log_pi = np.log(pi)\n",
    "        self.N = A.shape[0] # N is the number of possible states\n",
    "        self.M = B.shape[1] # M is the number of possible observations\n",
    "\n",
    "    def SampleFishFromPond(self, pond):\n",
    "        fish = np.random.choice(self.M, p = self.B[pond])\n",
    "        return fish\n",
    "\n",
    "\n",
    "    def CatchNextFish(self, curr_pond):\n",
    "        new_pond = np.random.choice(self.N, p = self.A[curr_pond])\n",
    "        fish = self.SampleFishFromPond(new_pond)\n",
    "        return new_pond, fish\n",
    "\n",
    "    def SimulateSystem(self):\n",
    "        ponds = np.empty(self.T, dtype = np.int32)\n",
    "        fishes = np.empty(self.T, dtype = np.int32)\n",
    "        ponds[0] = np.random.choice(4, p = self.pi)\n",
    "        fishes[0] = self.SampleFishFromPond(ponds[0])\n",
    "        for i in range(1, self.T):\n",
    "            new_pond, new_fish = self.CatchNextFish(ponds[i - 1])\n",
    "            ponds[i] = new_pond\n",
    "            fishes[i] = new_fish\n",
    "        self.ponds = ponds\n",
    "        self.fishes = fishes\n",
    "        return ponds, fishes\n",
    "    \n",
    "    def Forward(self):\n",
    "        # Remember that the forward algorithm only has accsses to the fishes\n",
    "        alpha = np.empty((self.T, self.N))\n",
    "        alpha[0] = pi * B[:, self.fishes[0]]\n",
    "        for t in range(1, self.T):\n",
    "            alpha[t] = np.dot(self.A.T, alpha[t - 1]) * B[:, self.fishes[t]]\n",
    "        return np.sum(alpha[-1])\n",
    "    \n",
    "    def Forward2(self):\n",
    "        log_alpha = np.empty((self.T, self.N))\n",
    "        log_alpha[0] = self.log_pi + self.log_B[:, self.fishes[0]]\n",
    "        for t in range(1, self.T):\n",
    "            for j in range(self.N):\n",
    "                log_alpha[t, j] = np.logaddexp.reduce(log_alpha[t - 1] + self.log_A[:, j]) + self.log_B[j, self.fishes[t]]\n",
    "        log_prob = np.logaddexp.reduce(log_alpha[-1])\n",
    "        return np.exp(log_prob)\n",
    "    \n",
    "    def Backward(self):\n",
    "        beta = np.ones((self.T, self.N))\n",
    "        for t in range(self.T - 2, -1, -1):\n",
    "            beta[t] = np.dot(self.A, beta[t + 1] * B[:, self.fishes[t + 1]]) \n",
    "        return np.sum(beta[0] * B[:, self.fishes[0]] * self.pi)\n",
    "    \n",
    "    def Backward2(self):\n",
    "        log_beta = np.zeros((self.T, self.N))\n",
    "        for t in range(self.T - 2, -1, -1):\n",
    "            for i in range(self.N):\n",
    "                log_beta[t, i] = np.logaddexp.reduce(self.log_A[i] + self.log_B[:, self.fishes[t + 1]] + log_beta[t + 1])\n",
    "        log_prob = np.logaddexp.reduce(log_beta[0] + self.log_B[:, self.fishes[0]] + self.log_pi)\n",
    "        return np.exp(log_prob)\n",
    "    \n",
    "    def Viterbi(self):\n",
    "        psi = np.zeros((self.T, self.N), dtype = np.int32)\n",
    "        delta = np.empty_like(psi, dtype = np.float32)\n",
    "        delta[0] = self.pi * self.B[:, self.fishes[0]]\n",
    "        for t in range(1, self.T):\n",
    "            A_T_times_delta = self.A.T * delta[t - 1] # Hadamar product between matrix and array\n",
    "            delta[t] = np.max(A_T_times_delta, axis = 1) * self.B[:, self.fishes[t]]\n",
    "            psi[t] = np.argmax(A_T_times_delta, axis = 1)\n",
    "        P = np.max(delta[-1])\n",
    "        q = np.empty(self.T, dtype = np.int32)\n",
    "        q[-1] = np.argmax(psi[-1])\n",
    "        for t in range(self.T - 2, -1, -1):\n",
    "            q[t] = psi[t + 1, q[t + 1]] \n",
    "        return P, q\n",
    "    \n",
    "    def Viterbi2(self):\n",
    "        psi = np.zeros((self.T, self.N), dtype = np.int32)\n",
    "        log_delta = np.empty_like(psi, dtype = np.float32)\n",
    "        log_delta[0] = self.log_pi + self.log_B[:, self.fishes[0]]\n",
    "        for t in range(1, self.T):\n",
    "            A_T_times_delta = self.log_A.T + log_delta[t - 1] # Hadamard product between matrix and array\n",
    "            log_delta[t] = np.max(A_T_times_delta, axis = 1) + self.log_B[:, self.fishes[t]]\n",
    "            psi[t] = np.argmax(A_T_times_delta, axis = 1)\n",
    "        log_P = np.max(log_delta[-1])\n",
    "        P = np.exp(log_P)\n",
    "        q = np.empty(self.T, dtype = np.int32)\n",
    "        q[-1] = np.argmax(psi[-1])\n",
    "        for t in range(self.T - 2, -1, -1):\n",
    "            q[t] = psi[t + 1, q[t + 1]] \n",
    "        return P, q\n",
    "    \n",
    "    def CompareAgainstFishSequence(self, q):\n",
    "        matches = np.sum(q == self.ponds)\n",
    "        accuracy = matches / self.T\n",
    "        print(\"Number of matches: \", matches)\n",
    "        print(\"Accuracy of the algorithm: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestSystem():\n",
    "    hmm = HMM(T, A, B, pi)\n",
    "    ponds, fishes = hmm.SimulateSystem()\n",
    "    print(\"Probability produced by forward procedure: \", hmm.Forward())\n",
    "    print(\"Probability produced by forward procedure (log variation): \", hmm.Forward2())\n",
    "    print(\"Probability produced by backward procedure: \", hmm.Backward())\n",
    "    print(\"Probability produced by backward procedure (log variation): \", hmm.Backward2())\n",
    "    P1, q1 = hmm.Viterbi()\n",
    "    P2, q2 = hmm.Viterbi2()\n",
    "    print(\"Probability produced by Viterbi: \", P1)\n",
    "    print(\"Probability produced by Viterbi (log variation): \", P2)\n",
    "    print(\"Comparing the actual sequence of states with the ones estimated by Viterbi:\")\n",
    "    hmm.CompareAgainstFishSequence(q1)\n",
    "    print(\"Comparing the actual sequence of states with the ones estimated by Viterbi (log variation):\")\n",
    "    hmm.CompareAgainstFishSequence(q2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "It is evident that the Viterbi algorithm performs much better when taking the $\\log$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability produced by forward procedure:  0.0\n",
      "Probability produced by forward procedure (log variation):  0.0\n",
      "Probability produced by backward procedure:  0.0\n",
      "Probability produced by backward procedure (log variation):  0.0\n",
      "Probability produced by Viterbi:  0.0\n",
      "Probability produced by Viterbi (log variation):  0.0\n",
      "Comparing the actual sequence of states with the ones estimated by Viterbi:\n",
      "Number of matches:  187\n",
      "Accuracy of the algorithm:  0.187\n",
      "Comparing the actual sequence of states with the ones estimated by Viterbi (log variation):\n",
      "Number of matches:  442\n",
      "Accuracy of the algorithm:  0.442\n"
     ]
    }
   ],
   "source": [
    "TestSystem()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the differences between forward and backward, we take $L = 700$. It seems that there is no major difference between the backward and forward procedures, even when taking log, as the two variations still return the same non-zero probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability produced by forward procedure:  1.368338147224397e-287\n",
      "Probability produced by forward procedure (log variation):  1.3683381472198267e-287\n",
      "Probability produced by backward procedure:  1.3683381472243932e-287\n",
      "Probability produced by backward procedure (log variation):  1.3683381472223156e-287\n",
      "Probability produced by Viterbi:  0.0\n",
      "Probability produced by Viterbi (log variation):  0.0\n",
      "Comparing the actual sequence of states with the ones estimated by Viterbi:\n",
      "Number of matches:  129\n",
      "Accuracy of the algorithm:  0.18428571428571427\n",
      "Comparing the actual sequence of states with the ones estimated by Viterbi (log variation):\n",
      "Number of matches:  348\n",
      "Accuracy of the algorithm:  0.49714285714285716\n"
     ]
    }
   ],
   "source": [
    "T = 700\n",
    "TestSystem()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
